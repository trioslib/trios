{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started with TRIOSlib\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table,tr,td {border:none!important}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table,tr,td {border:none!important}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document intends to give an overview of TRIOS and its main classes. If you are not familiar with $W$-operator learning, we suggest reading this [Introduction to Image Operator Learning](http://www.vision.ime.usp.br/projects/trios/basic_formulation/).\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td class=\"noborder\"> <img src=\"_static/image1.png\"> </td> <td> <img src=\"_static/image1-out.png\"> </td>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center;\"> (a) Example input image </td> <td style=\"text-align: center;\"> (b) Example output image </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\"> <small> source: <i> Visaniy, M.; Kieu, V.C.; Fornes, A.; Journet, N., \"ICDAR 2013 Music Scores Competition: Staff Removal,\" Document Analysis and Recognition (ICDAR), 2013 12th International Conference on , vol., no., pp.1407,1411, 25-28 Aug. 2013</i> </small> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "In a nutshell, $W$-operators are pixel classifiers that use only a small neighborhood around each point to determine its output value. The shape of the neighborhood is called *window*. The *Feature Extraction* phase consists in sliding the *window* over all pixels in the training images and recording the pairs *pattern-label* observed, forming a *training set* to train a *classifier*. This process is repeated to transform an image, but with the classifier filling the output image with the predicted pixel values. \n",
    "\n",
    "### Install \n",
    "\n",
    "(aqui vou colocar as futuras instruções de instalações usando pip.)\n",
    "\n",
    "Check if the *trios* module is installed by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import trios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images and imagesets\n",
    "\n",
    "The class `trios.Imageset` represents the sets of image pairs used to train $W$-operators. It is a subclass of `list` that stores tuples of 2 (`(input, output)`) or 3 (`(input, output, mask)`) elements. If a mask is present only the pixels which are nonzero at the mask are processed. \n",
    "\n",
    "`Imageset`s can be created in code as a list or we can use the methods `read`/`write` to load/save them from/to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jung/input1.png', 'jung/output1.png')]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'jung/level1.set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5a5bc4dc8346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimgset2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'jung/input1.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'jung/output1.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgset2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimgset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'jung/level1.set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Igor\\Anaconda3\\lib\\site-packages\\trios\\imageset.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(cls, fname)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mReads\u001b[0m \u001b[0mImageset\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdisk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \"\"\"\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mimgset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jung/level1.set'"
     ]
    }
   ],
   "source": [
    "imgset2 = trios.Imageset([('jung/input1.png', 'jung/output1.png')]) \n",
    "print(imgset2)\n",
    "imgset = trios.Imageset.read('jung/level1.set')\n",
    "print(imgset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `trios.shortcuts.persistence.load_image` function to load an image to use with `trioslib` and `trios.persistence.save_image` to save a result to the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows\n",
    "\n",
    "Windows are just 2D numpy arrays of type `uint8` where a point belongs to the window if its value is not zero. We can also create windows using the `trios.shortcuts.window` module. Choosing a good window is very important, as the subsequent steps depend on the distribution of the raw data to determine correctly the output pixel values. \n",
    "\n",
    "If the window choosen is to small we will not be able to discriminate spatially large patterns, no matter how clever are the feature extractor and classifier used. On the other hand, if a very big window is used, we risk overfitting the data and having bad generalization. Although some feature extraction methods and classifiers may mitigate this issue, it is still wise to carefully select windows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square\n",
      " [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "Rectangle\n",
      " [[1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Using numpy.ones\n",
    "import numpy as np\n",
    "win_np = np.ones((3, 3), np.uint8)\n",
    "# Or with the functions from trios.shortcuts.window\n",
    "from trios.shortcuts import window\n",
    "print('Square\\n', window.square(5))\n",
    "print('Rectangle\\n', window.rectangle(9, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training W-operators\n",
    "\n",
    "The `WOperator` class requires three parameters: a *window* (numpy array of type `np.uint`), a *FeatureExtractor* and a *Classifier*. Operators with very different characteristics can be obtained by combining these three components. In this tutorial we build a $W$-operator that uses pixel values as features (*RAWFeatureExtractor*) and a Decision Tree as classifier.\n",
    "\n",
    "We also demonstrate an important feature of `trioslib`: any classification method present in [scikit-learn](http://scikit-learn.org/) can be used as the classifier in a $W$-operator by wrapping it in the `trios.classifier.SKClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trios.feature_extractors import RAWFeatureExtractor\n",
    "from trios.classifiers import SKClassifier\n",
    "\n",
    "win = window.square(5)\n",
    "wop = trios.WOperator(win, SKClassifier(DecisionTreeClassifier()), RAWFeatureExtractor)\n",
    "wop.train(imageset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying W-operators and assessing their performance\n",
    "\n",
    "apply in an image using wop.apply, get error rate using wop.eval. Comment about multiprocessing stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading trained operators from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A operação da TRIOS está dividida em duas etapas: Extração de Características e Classificação. A primeira etapa é executada por objetos do tipo `FeatureExtractor` e, basicamente, posiciona a janela uma janela `window` sobre todos os pontos de todas as imagens de um `Imageset`. Em cada posição um `FeatureExtractor` faz um processamento local e extrai um vetor de características. Na segunda etapa um objeto do tipo `Classifier` é usado para determinar o valor de cada ponto da imagem de saída usando apenas o vetor de características extraído naquela posição na etapa anterior. Como toda informação usada é local, os operadores treinados são chamados de *window operators* ou $W-$operators.\n",
    "\n",
    "\n",
    "A operação mais simples possível é simplesmente copiar os valores de cada ponto da janela em um vetor. Isto é feito pelas classes `RAWFeatureExtractor` e `RAWBitFeatureExtractor`. A classe `RAWBit...` funciona somente para imagens binárias e codifica as features nos bits de um `uint32`. Ja a classe `RAWFeatureExtractor` funciona para imagens de cinza também, mas consome mais memória. \n",
    "\n",
    "Abaixo um exemplo de criação e utilização de um `FeatureExtractor`. O método `extract_dataset` faz a extração de características de um conjunto de imagens. Se o segundo parâmetro for `True` esta função retorna uma matrix `X` e um vetor `y` tal que cada linha de `X` contem um padrão extraído da imagem e sua posição correspondente em `y` contem sua saída esperada. Os padrões são armazenados em `X` na ordem em que são encontrados nas imagens.\n",
    "\n",
    "Se o segundo parâmetro for `False` o método retorna um dicionário que contém nas chaves os padrões encontrados e nos valores uma lista com a quantidade de vezes que um certo padrão apareceu em conjunto com cada valor de saída. É importante frisar que não é possível localizar a posição que um padrão ocorreu originalmente nas imagens de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trios.feature_extractors import RAWBitFeatureExtractor\n",
    "\n",
    "fext = RAWBitFeatureExtractor(window)\n",
    "dict_dataset = fext.extract_dataset(images, False)\n",
    "X, y = fext.extract_dataset(images, True)\n",
    "print(X.shape, X[100], y[100])\n",
    "\n",
    "keys = list(dict_dataset.keys())\n",
    "print(len(keys), dict_dataset[keys[10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trios contém diversos classificadores no pacote `trios.classifiers`. Selecionamos o *ISI (Incremental Splitting of Intervals)* para trabalhar com imagens binárias. Este classificador requer que utilizemos um `RAWBitFeatureExtractor` como extrator de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from trios.classifiers import ISI\n",
    "from trios.classifiers.ISI.isi import ISI\n",
    "cls = ISI(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construímos um $W-$operador simplesmente passamos estes três objetos para o construtor da classe. Suas duas principais funções são `train`, que recebe um conjunto de imagens e executa o treinamento do operador, e `apply`, que transforma uma imagem usando o operador treinado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wop = trios.WOperator(window, cls, fext)\n",
    "d = wop.train(images[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "path = images[-1][0]\n",
    "img = sp.ndimage.imread(path, mode='L')\n",
    "\n",
    "res = wop.apply(img, img)\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.cm import gray\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(121)\n",
    "imshow(img, cmap=gray)\n",
    "plt.subplot(122)\n",
    "imshow(res, cmap=gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operadores treinados pela TRIOS podem ser salvos usando o módulo `pickle` (opcionalmente em conjunto com o módulo `gzip`, para criar arquivos menores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('operador-salvo.gz', 'w') as f:\n",
    "    pickle.dump(wop, f, -1)\n",
    "    \n",
    "with gzip.open('operador-salvo.gz') as f:\n",
    "    wop2 = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
